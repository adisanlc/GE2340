<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Learning on Small Data</title>
</head>
<body>

  <header>
    <h1>Learning on Small Data: Finetuning Grounded-SAM for Mirror Detection</h1>
    <p>Adil ZHUMGALBEKOV, City University of Hong Kong, <a href="mailto:azhumgalb3-c@my.cityu.edu.hk">azhumgalb3-c@my.cityu.edu.hk</a></p>
    <p>Siu Tsun Wai, City University of Hong Kong, <a href="mailto:twsiu9-c@my.cityu.edu.hk">twsiu9-c@my.cityu.edu.hk</a></p>
  </header>

  <p>For reference on reproducing the process, you can consult the following resources:</p>

  <ul>
      <li><a href="https://github.com/open-mmlab/mmdetection/blob/main/configs/grounding_dino/README.md" style="color: blue;">mmdetection Grounding Dino Configurations</a></li>
      <li><a href="https://github.com/facebookresearch/segment-anything/blob/main/notebooks/predictor_example.ipynb" style="color: blue;">Segment Anything Model - Predictor Example Notebook</a></li>
  </ul>
  
  <p>We utilized ChatGPT for refining the language in this essay. You can explore more about ChatGPT <a href="https://www.openai.com/gpt" style="color: blue;">here</a>.</p>
  

  <section id="abstract">
    <h2>Abstract</h2>
    <p>Index Terms—Transfer Learning, Zero-Shot Learning, Mirror Detection</p>
    <p>Mirror segmentation is a challenging task due to its reflection property and existing solutions requires large amounts of data and manual annotations. In this paper, we propose a method of finetuning Grounding-DINO, a zero-shot object detector, on a small subset of the Mirror Segmentation Dataset (MSD) to enhance its performance on mirror detection. We then fuse Grounding-DINO with Segment Anything Model (SAM), a semantic segmentation model, to create Grounded-SAM, a model that can segment mirrors based on textual inputs. We evaluate our method on the MSD dataset and show that it outperforms the unfinetuned Grounding-SAM and is competitive with existing mirror segmentation models. We conclude that finetuning can help improve the performance of zero-shot models on specific tasks, and that Grounded-SAM can be applied to various downstream tasks that involve mirror segmentation.
    </p>
    <!-- Add more content as needed -->
  </section>

  <section id="introduction">
    <h2>Dataset Preparation:</h2>
    <p>Utilizing Grounding DINO for mirror detection, we select a subset of the Mirror Segmentation Dataset (MSD). Despite its focus on segmentation, Grounding DINO's pre-trained knowledge compensates for the limited size of our training sample. We convert segmentation masks into bounding box annotations, bridging the gap for object detection.</p>
    <p>All datasets can be found on GitHub: <a href="https://github.com/adisanlc/GE2340.git" style="color: blue;">https://github.com/adisanlc/GE2340.git</a></p>

    <!-- Add more content as needed -->
  </section>

  <section id="introduction">
    <h2>Finetuning Details:</h2>
    <p>Utilizing MMDe-tction’s framework, we make specific alterations to fine-tune Grounding-Dino. Pre-trained weights from diverse datasets enrich the model's knowledge, enhancing feature extraction for mirror detection. Despite the original architecture's retention, adjustments to optimizer settings, learning rate, and scheduler are crucial. Finetuning over 20 epochs yields superior results, with the final weights selected based on mean Average Precision (mAP).</p>
    <p>Grounded-SAM, a fusion of Grounding-DINO and Segment Anything Model (SAM), excels in zero-shot segmentation. SAM's segmentation skills, combined with Grounding-DINO's bounding box generation, form a powerful tool for mirror segmentation. ViT-H SAM, with official pre-trained weights, facilitates the inference process.</p>
    <!-- Add more content as needed -->
  </section>

  <!-- Add more sections for RELATED WORK, DESCRIPTION, EVALUATION, etc. -->

  <section id="training-data">
    <h2>MSD_COCO Training Data</h2>
    <div class="image-gallery">
        <!-- Display training images from the 'train' folder -->
        <h3>Training Images</h3>
        <div class="image-container">
            <!-- Add image tags dynamically based on your dataset structure -->
            <img src="MSD_COCO/train/image/7_512x640.jpg" alt="Training Image 1">
            <img src="MSD_COCO/train/image/9_640x512.jpg" alt="Training Image 2">
            <img src="MSD_COCO/train/image/10_512x640.jpg" alt="Training Image 3">
            <img src="MSD_COCO/train/image/23_512x640.jpg" alt="Training Image 4">
            <!-- Add more images as needed -->
        </div>

        <!-- Display corresponding masks from the 'train' folder -->
        <h3>Training Masks</h3>
        <div class="image-container">
            <!-- Add mask image tags dynamically based on your dataset structure -->
            <img src="MSD_COCO/train/mask/7_512x640.png" alt="Training Mask 1">
            <img src="MSD_COCO/train/mask/9_640x512.png" alt="Training Mask 2">
            <img src="MSD_COCO/train/mask/10_512x640.png" alt="Training Mask 3">
            <img src="MSD_COCO/train/mask/23_512x640.png" alt="Training Mask 4">
            <!-- Add more masks as needed -->
        </div>
    </div>
  </section>

  <section id="testing-data">
    <h2>Testing Data</h2>
    <div class="image-gallery">
        <!-- Display testing images from the 'test' folder -->
        <h3>Testing Images</h3>
        <div class="image-container">
            <!-- Add image tags dynamically based on your dataset structure -->
            <img src="MSD_COCO/test/image/22_512x640.jpg" alt="Testing Image 1">
            <img src="MSD_COCO/test/image/5129_512x640.jpg" alt="Testing Image 2">
            <img src="MSD_COCO/test/image/66_512x640.jpg" alt="Testing Image 1">
            <img src="MSD_COCO/test/image/318_512x640.jpg" alt="Testing Image 2">
            <!-- Add more images as needed -->
        </div>

        <!-- Display corresponding masks from the 'test' folder -->
        <h3>Testing Masks</h3>
        <div class="image-container">
            <!-- Add mask image tags dynamically based on your dataset structure -->
            <img src="MSD_COCO/test/mask/22_512x640.png" alt="Testing Mask 1">
            <img src="MSD_COCO/test/mask/5129_512x640.png" alt="Testing Mask 2">
            <img src="MSD_COCO/test/mask/66_512x640.png" alt="Testing Mask 1">
            <img src="MSD_COCO/test/mask/318_512x640.png" alt="Testing Mask 2">
            <!-- Add more masks as needed -->
        </div>
    </div>
  </section>

  

</section>

<section id="grounding-dino-results">
  <h2>Grounding Dino Results</h2>
  <p>The finetuned model significantly outperforms the unfinetuned across all metrics, demonstrating remarkable improvement in object detection accuracy, especially at higher IoU thresholds. The model's effectiveness in detecting mirrors and generating accurate bounding boxes is evident.  </p>

  <div class="image-gallery" id="unfinetuned-gallery">
      <h3>Unfinetuned Images</h3>
      <div class="image-container">
          <!-- Add image tags for unfinetuned images dynamically based on your dataset structure -->
          <img src="Grounding_Dino_Results/unfinetuned/22_512x640.jpg" alt="Unfinetuned Image 1">
          <img src="Grounding_Dino_Results/unfinetuned/5129_512x640.jpg" alt="Unfinetuned Image 2">
          <img src="Grounding_Dino_Results/unfinetuned/66_512x640.jpg" alt="Finetuned Image 3">
          <img src="Grounding_Dino_Results/unfinetuned/318_512x640.jpg" alt="Finetuned Image 4">
          <!-- Add more unfinetuned images as needed -->
      </div>
  </div>

  <div class="image-gallery" id="finetuned-gallery">
      <h3>Finetuned Images</h3>
      <div class="image-container">
          <!-- Add image tags for finetuned images dynamically based on your dataset structure -->
          <img src="Grounding_Dino_Results/finetuned/22_512x640.jpg" alt="Finetuned Image 1">
          <img src="Grounding_Dino_Results/finetuned/5129_512x640.jpg" alt="Finetuned Image 2">
          <img src="Grounding_Dino_Results/finetuned/66_512x640.jpg" alt="Finetuned Image 3">
          <img src="Grounding_Dino_Results/finetuned/318_512x640.jpg" alt="Finetuned Image 4">
          <!-- Add more finetuned images as needed -->
      </div>
  </div>

<section id="grounding-sam-results">
  <h2>Grounding SAM Results</h2>

  <p>A comprehensive quantitative comparison with existing models showcases the significant improvement of the finetuned Grounded-SAM. Despite a substantially smaller training dataset, the finetuned model achieves lower MAE and higher IoU and Fβ scores, highlighting its efficiency in challenging mirror detection.</p>
  <div class="image-gallery" id="unfinetuned-gallery">
      <h3>Unfinetuned Images</h3>
      <div class="image-container">
          <!-- Add image tags for unfinetuned images dynamically based on your dataset structure -->
          <img src="Grounded_SAM_results/unfinetuned_masks/22_512x640.png" alt="Unfinetuned Image 1">
          <img src="Grounded_SAM_results/unfinetuned_masks/5129_512x640.png" alt="Unfinetuned Image 2">
          <img src="Grounded_SAM_results/unfinetuned_masks/66_512x640.png" alt="Unfinetuned Image 3">
          <img src="Grounded_SAM_results/unfinetuned_masks/318_512x640.png" alt="Unfinetuned Image 4">
          <!-- Add more unfinetuned images as needed -->
      </div>
  </div>

  <div class="image-gallery" id="finetuned-gallery">
      <h3>Finetuned Images</h3>
      <div class="image-container">
          <!-- Add image tags for finetuned images dynamically based on your dataset structure -->
          <img src="Grounded_SAM_results/finetuned_masks/22_512x640.png" alt="Finetuned Image 1">
          <img src="Grounded_SAM_results/finetuned_masks/5129_512x640.png" alt="Finetuned Image 2">
          <img src="Grounded_SAM_results/finetuned_masks/66_512x640.png" alt="Finetuned Image 3">
          <img src="Grounded_SAM_results/finetuned_masks/318_512x640.png" alt="Finetuned Image 4">
          <!-- Add more finetuned images as needed -->
      </div>
  </div>

</section>

<section id="introduction">
  <h2>Results</h2>
  <p>Comparisons between unfinetuned and finetuned models, alongside state-of-the-art counterparts, reveal the superior performance of the finetuned Grounded-SAM. Notably, the finetuned model reduces segmentation errors and occasionally outperforms established systems, emphasizing its efficacy in mirror detection.
  </p>
    <p>In conclusion, our work demonstrates the effectiveness of fine-tuning Grounding-Dino and Grounded-SAM for mirror detection, even with limited data. The results open new possibilities for applying these models in various computer vision tasks, showcasing their versatility and practical utility.</p>
  <!-- Add more content as needed -->
</section>



</body>
</html>
